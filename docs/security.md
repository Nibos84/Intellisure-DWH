# Security Documentation

## Overview

The Agentic Data Engineering System implements multiple layers of security to protect against malicious code execution, unauthorized access, and data breaches.

**Security Layers:**
1. **Code Validation** - Prevents execution of dangerous LLM-generated scripts
2. **Input Validation** - Validates manifest configurations before execution
3. **Secrets Management** - Secure credential handling via S3 pre-signed URLs
4. **Resource Exhaustion Protection** - Execution timeouts to prevent runaway scripts
5. **Rate Limiting** (Planned) - Prevents API abuse and cost overruns

---

## Code Validation & Sandboxing

### Purpose

Prevent execution of malicious or dangerous LLM-generated Python scripts by validating code before execution.

### Implementation

**Module:** `src/security/code_validator.py`

The `CodeValidator` class uses Abstract Syntax Tree (AST) parsing to analyze Python code without executing it.

### Security Checks

#### 1. Dangerous Import Detection

**Blocked Imports:**
- `os.system` - System command execution
- `subprocess` - Process spawning
- `eval`, `exec`, `compile` - Dynamic code execution
- `__import__`, `importlib` - Dynamic imports
- `socket`, `telnetlib`, `ftplib`, `smtplib` - Direct network access
- `pickle`, `shelve`, `marshal` - Arbitrary code execution via deserialization
- `ctypes`, `cffi` - Foreign function interface (can bypass Python security)

**Allowed Imports:**
- Data processing: `pandas`, `numpy`, `pyarrow`
- Cloud/S3: `boto3`, `botocore`
- HTTP: `requests`, `urllib`, `urllib3`
- Standard library: `json`, `csv`, `datetime`, `time`, `re`, `typing`, `io`, `pathlib`, `collections`, `itertools`, `functools`, `math`, `statistics`, `hashlib`, `uuid`, `base64`, `logging`

#### 2. Dangerous Function Call Detection

**Blocked Functions:**
- `eval()` - Evaluates arbitrary code
- `exec()` - Executes arbitrary code
- `compile()` - Compiles arbitrary code
- `__import__()` - Dynamic imports
- `open()` - File operations (warned, not blocked)
- `input()` - Interactive input (not suitable for automated scripts)

#### 3. Syntax & Compilation Validation

- **Syntax Check:** Ensures code is valid Python
- **Compilation Check:** Verifies code can be compiled
- **Error Reporting:** Provides detailed error messages and suggestions

### Usage

#### Basic Usage

```python
from src.security.code_validator import CodeValidator

validator = CodeValidator()

# Validate code
code = '''
import pandas as pd
df = pd.DataFrame({'a': [1, 2, 3]})
'''

is_valid, error_msg, suggestions = validator.validate(code)

if is_valid:
    print("Code is safe to execute")
else:
    print(f"Validation failed: {error_msg}")
    print(f"Suggestions: {suggestions}")
```

#### Integration with Agents

Both `IngestionSpecialistAgent` and `TransformationSpecialistAgent` automatically validate generated code:

```python
from src.agents.mas.ingestion_specialist import IngestionSpecialistAgent

agent = IngestionSpecialistAgent()

# Agent will:
# 1. Generate script via LLM
# 2. Validate script with CodeValidator
# 3. If invalid: retry with feedback (max 3 attempts)
# 4. If valid: execute script

result = agent.execute(manifest)
```

### Retry Logic with LLM Feedback

When validation fails, the agent provides feedback to the LLM:

```
Attempt 1: LLM generates code with subprocess
           ‚ùå Validation fails: "Dangerous import: subprocess"
           
Attempt 2: LLM receives feedback and generates corrected code
           ‚úÖ Validation passes
           
Script executes successfully
```

**Max Retries:** 3 attempts  
**Feedback Format:** Error message + Suggestions for fixes

### Validation Report

Get detailed validation report:

```python
validator.validate(code)
report = validator.get_validation_report()
print(report)
```

**Example Output:**
```
ERRORS:
  ‚ùå Dangerous import detected: 'subprocess'

SUGGESTIONS:
  üí° Remove 'subprocess' - this import is not allowed for security reasons
  üí° Use boto3 or requests instead of system calls
```

---

## Resource Exhaustion Protection

### Execution Timeouts

**Implementation:** `src/utils/execution.py`, `src/agents/mas/ingestion_specialist.py`, `src/agents/mas/transformation_specialist.py`

**Purpose:** Prevent runaway scripts from consuming excessive resources.

**Mechanism:**
- Python `signal.alarm()` based timeout
- Default: 300 seconds (5 minutes)
- Configurable via `SCRIPT_EXECUTION_TIMEOUT` environment variable

**Example:**
```python
from src.utils.execution import time_limit, TimeoutException

try:
    with time_limit(300):
        result = subprocess.run([sys.executable, script_path])
except TimeoutException as e:
    logger.error(f"Script execution timed out")
    return {"status": "failed", "error": "Script execution timed out"}
```

**What Happens on Timeout:**
1. Script process receives SIGALRM signal
2. `TimeoutException` is raised
3. Agent returns `{"status": "failed", "error": "Script execution timed out"}`
4. User is notified via logs

**Why 5 Minutes?**
- Sufficient for most public API ingestions
- Prevents infinite loops
- Protects against memory bombs
- Balances between functionality and safety

**Configuration:**
```bash
# .env
SCRIPT_EXECUTION_TIMEOUT=300  # seconds
```

**Testing:**
```bash
pytest tests/test_execution_timeouts.py -v
```

**Limitations:**
- **Cross-Platform:** Works on Windows, Unix/Linux, macOS via `subprocess.run(timeout=...)`
- **Signal-based timeout (Unix/Linux only):** Additional safety layer using `signal.SIGALRM`
- **Windows:** Signal-based timeout is disabled (not supported), relies solely on subprocess timeout
- **Windows Process Trees:** `subprocess.run(timeout=...)` may not terminate child processes spawned by the script

**Platform-Specific Behavior:**

| Platform | Subprocess Timeout | Signal Timeout | Total Protection |
|----------|-------------------|----------------|------------------|
| Windows  | ‚úÖ Yes            | ‚ùå No (N/A)    | ‚úÖ Full*         |
| Unix/Linux | ‚úÖ Yes          | ‚úÖ Yes (extra) | ‚úÖ Full + Extra  |
| macOS    | ‚úÖ Yes            | ‚úÖ Yes (extra) | ‚úÖ Full + Extra  |

*Note: Windows timeout may not reliably terminate scripts that spawn child processes.

**Why Dual Timeout?**
- `subprocess.run(timeout=...)` is the **primary** cross-platform timeout
- `signal.SIGALRM` (Unix/Linux) provides **additional** OS-level safety if subprocess timeout fails
- Both layers ensure scripts cannot run indefinitely (Unix/Linux gets best protection)

---

## Secrets Management

### Purpose

Prevent credential exposure in LLM-generated scripts by using S3 pre-signed URLs instead of passing raw credentials.

### Problem Statement

**Before:** Credentials (`OVH_ACCESS_KEY`, `OVH_SECRET_KEY`) were passed to generated scripts via environment variables. This created security risks:
- Scripts could log credentials to stdout/stderr
- Scripts could exfiltrate credentials to external services
- Scripts could store credentials in files
- Credentials visible in process listings

**After:** Scripts receive time-limited pre-signed URLs for specific S3 operations. No credentials are exposed.

### Implementation

**Module:** `src/security/s3_credential_service.py`

The `S3CredentialService` generates pre-signed URLs for S3 operations without exposing raw credentials to generated scripts.

#### Key Features

‚úÖ **No Credential Exposure:** Scripts never see `OVH_ACCESS_KEY` or `OVH_SECRET_KEY`  
‚úÖ **Time-Limited Access:** URLs expire automatically (default: 1 hour, configurable)  
‚úÖ **Operation-Specific:** Upload URLs can't download, download URLs can't upload  
‚úÖ **Audit Trail:** All URL generation is logged with timestamps  
‚úÖ **Principle of Least Privilege:** Scripts only get access to specific S3 objects

### Configuration

**Environment Variable:**
```bash
# S3 Pre-Signed URL Expiration (seconds)
PRESIGNED_URL_EXPIRATION=3600  # Default: 1 hour
```

### Usage Example

#### Ingestion Specialist

**Before (‚ùå Credentials Exposed):**
```python
env_vars.update({
    "OVH_ACCESS_KEY": config.ovh_access_key,  # ‚ùå Exposed
    "OVH_SECRET_KEY": config.ovh_secret_key,  # ‚ùå Exposed
})
```

**After (‚úÖ Presigned URLs):**
```python
from src.security.s3_credential_service import S3CredentialService

s3_service = S3CredentialService(
    endpoint_url=config.ovh_endpoint,
    region_name=config.ovh_region,
    access_key=config.ovh_access_key,  # Kept secure in service
    secret_key=config.ovh_secret_key,  # Kept secure in service
)

presigned_url = s3_service.generate_presigned_upload_url(
    bucket="my-bucket",
    key="landing/api/data.json",
    expiration=config.script_execution_timeout + 300
)

env_vars.update({
    "S3_UPLOAD_URL": presigned_url,  # ‚úÖ Time-limited URL
})
```

**Generated Script (uses requests, not boto3):**
```python
import requests
import os

upload_url = os.environ['S3_UPLOAD_URL']
response = requests.put(
    upload_url,
    data=json_data,
    headers={'Content-Type': 'application/json'}
)
```

### Security Benefits

| Aspect | Before | After |
|--------|--------|-------|
| **Credential Visibility** | ‚ùå Visible in env vars | ‚úÖ Hidden in service |
| **Script Access** | ‚ùå Full S3 access | ‚úÖ Single object only |
| **Time Limit** | ‚ùå Permanent credentials | ‚úÖ URLs expire automatically |
| **Exfiltration Risk** | ‚ùå High | ‚úÖ Low (time-limited) |

### Limitations

‚ö†Ô∏è **URL Expiration:** Scripts must complete before URL expires (default: 1 hour)  
‚ö†Ô∏è **Single Object:** Pre-signed URLs work for single objects, not batch operations  
‚ö†Ô∏è **No List Operations:** Can't list S3 buckets with pre-signed URLs

**Testing:** `tests/test_s3_credential_service.py`

---

## Network Access Control

### Public-Only URL Validation

**Implementation:** `src/schemas/manifest_schemas.py` - `SourceConfig.validate_public_url()`

**Purpose:** Ensure data sources are publicly accessible, preventing:
- Access to internal services
- Private network scanning
- Localhost exploitation
- Server-Side Request Forgery (SSRF) attacks

**Blocked URL Patterns:**

1. **Localhost:**
   - `localhost`, `127.0.0.1`, `::1`, `0.0.0.0`

2. **Private IP Ranges (RFC 1918):**
   - `10.0.0.0/8` (Class A private network)
   - `172.16.0.0/12` (Class B private network)
   - `192.168.0.0/16` (Class C private network)

3. **Special Use IPs:**
   - `169.254.0.0/16` (Link-local addresses)
   - Reserved ranges
   - Loopback addresses

4. **Private Hostname Patterns:**
   - Contains: `internal`, `corp`, `intranet`
   - Ends with: `.local`, `.lan`

**Examples:**

‚úÖ **Allowed:**
```yaml
source:
  url: "https://api.data.gov/api/v1/data"
  url: "https://opendata.cbs.nl/ODataApi/odata"
  url: "https://dummyjson.com/products"
  url: "https://example.com/api"
```

‚ùå **Blocked:**
```yaml
source:
  url: "http://localhost:8080/api"          # Localhost
  url: "http://192.168.1.1/data"           # Private IP
  url: "http://10.0.0.1/secret"            # Private IP
  url: "http://internal.company.com/api"   # Private hostname
```

**Error Messages:**
```
‚ùå Manifest validation failed:
  ‚Ä¢ source -> url: Localhost URLs not allowed: localhost. 
    This platform is for public data sources only.

‚ùå Manifest validation failed:
  ‚Ä¢ source -> url: Private/reserved IP address not allowed: 192.168.1.1. 
    This platform is for public data sources only. Use public domain names instead.

‚ùå Manifest validation failed:
  ‚Ä¢ source -> url: Private hostname pattern detected: internal.company.com. 
    This platform is for public data sources only.
```

**Testing:**
```bash
pytest tests/test_manifest_schemas.py::test_url_validation_blocks_localhost -v
pytest tests/test_manifest_schemas.py::test_url_validation_blocks_private_ips -v
pytest tests/test_manifest_schemas.py::test_url_validation_blocks_private_hostnames -v
pytest tests/test_manifest_schemas.py::test_url_validation_allows_public_urls -v
```

**Known Limitations:**

‚ö†Ô∏è **DNS Rebinding Attacks:**
- Attacker could use DNS that resolves to private IP after validation
- **Current Mitigation:** None
- **Recommendation:** Re-validate hostname at request time (future enhancement)

‚ö†Ô∏è **URL Redirects:**
- Public URL could redirect to private IP
- **Current Mitigation:** None
- **Recommendation:** Disable redirects in requests library (future enhancement)

---

## Best Practices

### For Developers

1. **Always validate generated code** before execution
2. **Review validation logs** regularly to identify false positives
3. **Update allowlist** when adding new safe dependencies
4. **Test with malicious inputs** to ensure validator catches threats

### For Operations

1. **Monitor validation failures** in production logs
2. **Alert on repeated failures** (may indicate LLM issues)
3. **Audit blocked code** for security analysis
4. **Keep validator updated** with new threat patterns

---

## Security Levels

### Current Implementation (Point 1 Complete)

‚úÖ **Code Validation**
- AST-based analysis
- Dangerous import/function blocking
- Syntax validation
- Retry logic with LLM feedback

### Planned Enhancements

‚è≥ **Input Validation** (Point 2)
- Manifest schema validation
- Type checking
- Value range validation

‚è≥ **Secrets Management** (Point 3)
- Credential rotation
- Vault integration
- Temporary credentials

‚è≥ **Rate Limiting** (Point 5)
- LLM call throttling
- Cost tracking
- Circuit breaker pattern

---

## Threat Model

### Threats Mitigated

| Threat | Mitigation | Status |
|--------|------------|--------|
| Malicious code injection | AST validation | ‚úÖ Implemented |
| System command execution | Import blocking | ‚úÖ Implemented |
| Data exfiltration via network | Socket blocking | ‚úÖ Implemented |
| Arbitrary code execution | eval/exec blocking | ‚úÖ Implemented |
| Resource exhaustion | Execution timeouts | ‚úÖ Implemented |
| Private network access | URL validation | ‚úÖ Implemented |
| Credential theft | (Planned) Secrets management | ‚è≥ Pending |

### Residual Risks

1. **LLM Prompt Injection:** Malicious prompts could trick LLM into generating harmful code
   - **Mitigation:** Validator catches most dangerous patterns
   - **Recommendation:** Implement prompt sanitization

2. **DNS Rebinding:** URL could resolve to private IP after validation
   - **Mitigation:** None (currently)
   - **Recommendation:** Re-validate hostname at request time

3. **URL Redirects:** Public URL could redirect to private IP
   - **Mitigation:** None (currently)
   - **Recommendation:** Disable redirects in requests library

4. **Logic Bugs:** Generated code could have business logic errors
   - **Mitigation:** None (currently)
   - **Recommendation:** Add data quality validation

---

## Testing

### Unit Tests

**File:** `tests/test_code_validator.py`

Run tests:
```bash
pytest tests/test_code_validator.py -v
```

**Coverage:**
- Dangerous import detection (7 tests)
- Safe import allowance (5 tests)
- Syntax validation (3 tests)
- Realistic scenarios (2 tests)
- Edge cases (3 tests)

### Manual Testing

Validate the system with known malicious code:

```bash
python -c "
from src.security.code_validator import CodeValidator
v = CodeValidator()
print('Test 1:', not v.validate('import os; os.system(\"test\")')[0])
print('Test 2:', v.validate('import pandas as pd')[0])
"
```

Expected output:
```
Test 1: True  (dangerous code blocked)
Test 2: True  (safe code allowed)
```

---

## Compliance

### GDPR Considerations

- **Data Minimization:** Validator only logs error messages, not full code
- **Audit Trail:** All validation failures are logged
- **Right to Explanation:** Detailed error messages explain why code was blocked

### Industry Standards

- **OWASP Top 10:** Addresses A03:2021 - Injection
- **CWE-94:** Improper Control of Generation of Code (Code Injection)
- **CWE-95:** Improper Neutralization of Directives in Dynamically Evaluated Code

---

## Incident Response

### If Malicious Code is Detected

1. **Immediate:** Code execution is blocked
2. **Logging:** Validation failure is logged with details
3. **Alert:** (Planned) Security team is notified
4. **Analysis:** Review LLM prompt and context
5. **Remediation:** Update validator rules if needed

### If Malicious Code Bypasses Validator

1. **Immediate:** Kill running process
2. **Containment:** Isolate affected system
3. **Analysis:** Determine how code bypassed validator
4. **Update:** Add new detection rules
5. **Audit:** Review all recent executions

---

## Configuration

### Environment Variables

No configuration required. Validator uses hardcoded allowlists for security.

### Customization

To add allowed imports, edit `src/security/code_validator.py`:

```python
ALLOWED_IMPORTS = {
    # Existing imports...
    'your_safe_library',  # Add your library
}
```

**‚ö†Ô∏è Warning:** Only add libraries after security review!

---

## Monitoring & Logging

### Log Levels

- **INFO:** Validation passed
- **WARNING:** Validation failed, retrying
- **ERROR:** Max retries reached, execution blocked

### Example Logs

```
2026-02-16 21:00:00 - INFO - [Ingestion Specialist] ‚úÖ Script validation passed
2026-02-16 21:00:05 - WARNING - [Transformation Specialist] ‚ùå Script validation failed: Dangerous import detected: 'subprocess'
2026-02-16 21:00:10 - ERROR - [Ingestion Specialist] Max retries reached. Validation report:
ERRORS:
  ‚ùå Dangerous import detected: 'os.system'
```

---

## FAQ

**Q: Why block `os` module entirely?**  
A: We only block dangerous functions like `os.system`. Safe uses like `os.environ.get()` are allowed.

**Q: What if I need a blocked import?**  
A: Submit a security review request. If approved, add to allowlist.

**Q: Can the LLM bypass the validator?**  
A: No. Validation happens after code generation, before execution.

**Q: What's the performance impact?**  
A: Minimal. AST parsing takes <10ms per script.

**Q: How do I test the validator?**  
A: Run `pytest tests/test_code_validator.py -v`

---

## References

- [Python AST Documentation](https://docs.python.org/3/library/ast.html)
- [OWASP Code Injection](https://owasp.org/www-community/attacks/Code_Injection)
- [CWE-94: Code Injection](https://cwe.mitre.org/data/definitions/94.html)

---

**Last Updated:** 16 februari 2026  
**Version:** 1.0  
**Status:** Production Ready (with remaining critical points)
