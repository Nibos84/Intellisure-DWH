# Agentic Data Engineering System

> **Autonomous data pipelines powered by AI agents**

A Multi-Agent System (MAS) that transforms natural language requests into fully functional data pipelines. Describe what you want, and the system analyzes, designs, builds, and executes the pipeline automatically.

---

## ğŸš€ Quick Start

### 1. Setup

```bash
# Clone the repository
git clone <repo-url>
cd data_engineering_agents

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your OVH S3 and OpenAI credentials
```

### 2. Run Interactive Mode

```bash
python interact.py
```

**Example Interaction:**
```
> Ingest data from https://dummyjson.com/recipes

ğŸ•µï¸  RESEARCHER: DummyJSON provides a REST API at /recipes with JSON format...
ğŸ—ï¸  ARCHITECT: Proposed Plan - Fetch via GET, store in layer=landing/source=dummyjson...

Approve this plan? (y/n): y

ğŸ› ï¸  ENGINEER: Generated manifests/mas_ingest_data_from_dum.yaml

Execute this pipeline? (y/n): y

ğŸ“¥ INGESTION SPECIALIST: Analyzing API... Fetching 30 records... âœ… Complete
```

---

## ğŸ§  Architecture

The system consists of **5 AI agents** working together:

### Planning Agents
- **Researcher** ğŸ•µï¸ - Analyzes data sources (API structure, format, pagination)
- **Architect** ğŸ—ï¸ - Designs pipeline strategy (Landing â†’ Silver â†’ Gold)
- **Engineer** ğŸ› ï¸ - Generates YAML manifests

### Execution Agents
- **Ingestion Specialist** ğŸ“¥ - Fetches data with intelligent error handling
- **Transformation Specialist** ğŸ”„ - Transforms data with schema inference

**Key Innovation:** All agents use LLM reasoning. No hardcoded logic.

---

## ğŸ“ Project Structure

```
data_engineering_agents/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ mas/                    # Multi-Agent System
â”‚   â”‚       â”œâ”€â”€ base_role.py        # AgentRole base class
â”‚   â”‚       â”œâ”€â”€ roles.py            # Planning agents
â”‚   â”‚       â”œâ”€â”€ orchestrator.py     # Workflow coordinator
â”‚   â”‚       â”œâ”€â”€ ingestion_specialist.py
â”‚   â”‚       â””â”€â”€ transformation_specialist.py
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ ai_service.py           # OpenAI wrapper
â”‚       â”œâ”€â”€ config.py               # Configuration
â”‚       â”œâ”€â”€ runner.py               # Pipeline executor
â”‚       â””â”€â”€ s3_manager.py           # S3 operations
â”œâ”€â”€ manifests/                      # Generated YAML configs
â”œâ”€â”€ interact.py                     # Interactive CLI
â”œâ”€â”€ main.py                         # Direct manifest runner
â””â”€â”€ README.md
```

---

## ğŸ¯ Use Cases

### 1. Ingest New API
```
> Ingest weather data from KNMI API
```
â†’ System analyzes API, generates manifest, fetches data to S3

### 2. Transform Data
```
> Transform Rechtspraak XML to JSON with ECLI and date fields
```
â†’ System reads Landing data, applies AI transformation, writes to Silver

### 3. Custom Pipelines
```
> Fetch products from Shopify and enrich with pricing data
```
â†’ System designs multi-step pipeline with your requirements

---

## ğŸ› ï¸ Manual Pipeline Execution

You can also run manifests directly:

```bash
python main.py --manifest manifests/rechtspraak.yaml --env dev
```

---

## ğŸ“š Documentation

- **[Functional Documentation](docs/functional_documentation.md)** - What the system does (user guide)
- **[Technical Documentation](docs/technical_documentation.md)** - How it works (architecture, code)

---

## ğŸ”§ Configuration

### Environment Variables (`.env`)

```bash
# OVH S3 Storage
OVH_ACCESS_KEY=your_access_key
OVH_SECRET_KEY=your_secret_key
OVH_ENDPOINT=https://s3.rbx.io.cloud.ovh.net
OVH_REGION=rbx

# OpenAI
OPENAI_API_KEY=your_openai_key

# Environment
ENV=dev  # dev | prd
LLM_MODEL=gpt-3.5-turbo
```

---

## ğŸ§ª Testing

Run the MAS test:
```bash
python test_mas.py
```

This simulates the full agent workflow and validates YAML generation.

---

## ğŸ—ï¸ Data Lake Structure

Data is stored in **Hive-partitioned** S3 buckets:

```
s3://splendid-bethe/
â”œâ”€â”€ layer=landing/
â”‚   â””â”€â”€ source=rechtspraak/
â”‚       â””â”€â”€ dataset=uitspraken/
â”‚           â””â”€â”€ year=2026/month=02/day=15/
â”‚               â””â”€â”€ batch_20260215120000.json
â””â”€â”€ layer=silver/
    â””â”€â”€ source=rechtspraak/
        â””â”€â”€ dataset=uitspraken/
            â””â”€â”€ year=2026/month=02/day=15/
                â””â”€â”€ batch_20260215120000.parquet
```

**Layers:**
- **Landing**: Raw data as fetched from source
- **Silver**: Cleaned, structured data
- **Gold**: Business-ready aggregations (future)

---

## ğŸš§ Roadmap

- [x] Phase 1: Core ingestion & transformation agents
- [x] Phase 2: Multi-Agent System (MAS)
  - [x] Planning agents (Researcher, Architect, Engineer)
  - [x] Execution agents (Ingestion/Transformation Specialists)
- [ ] Phase 3: Deployment
  - [ ] VPS deployment
  - [ ] CI/CD pipeline
  - [ ] Scheduled runs

---

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ¤ Contributing

This is an experimental prototype. Contributions welcome!

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## âš ï¸ Limitations

- **LLM Dependency**: Requires OpenAI API access
- **Cost**: Each agent interaction consumes tokens
- **Experimental**: Not production-ready without additional validation

---

**Built with â¤ï¸ using OpenAI GPT-3.5 and OVH Cloud**
